{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/cameronfaulkner/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cameronfaulkner/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rawContent</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>links</th>\n",
       "      <th>media</th>\n",
       "      <th>mentionedUsers</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Party</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Year’s Day in Seward overlooking the harbo...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy #NewYear!</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I championed provisions to strengthen Alaska’s...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>December: As senior Appropriator, I helped wri...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>December: Congressman Don Young’s legacy will ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          rawContent  replyCount  \\\n",
       "0  New Year’s Day in Seward overlooking the harbo...        44.0   \n",
       "1                                    Happy #NewYear!        19.0   \n",
       "2  I championed provisions to strengthen Alaska’s...         9.0   \n",
       "3  December: As senior Appropriator, I helped wri...        11.0   \n",
       "4  December: Congressman Don Young’s legacy will ...         5.0   \n",
       "\n",
       "   retweetCount  likeCount  quoteCount  links  media  mentionedUsers  \\\n",
       "0          12.0      239.0         2.0      0      3               0   \n",
       "1           4.0       22.0         1.0      0      0               0   \n",
       "2           5.0       19.0         0.0      0      0               0   \n",
       "3           6.0       28.0         3.0      0      1               0   \n",
       "4           9.0       46.0         1.0      0      1               0   \n",
       "\n",
       "   hashtags  Party  Positive  Negative  Neutral  \n",
       "0         0      1         1         0        0  \n",
       "1         1      1         1         0        0  \n",
       "2         0      1         1         0        0  \n",
       "3         0      1         1         0        0  \n",
       "4         0      1         1         0        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"/Users/cameronfaulkner/Documents/Cogs 118a/Final Project/Sentiment Added Dataset\")\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Test to Maximize Classifier Performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(ds: pd.Series) -> pd.Series:\n",
    "    for m in range(len(ds)):\n",
    "        \n",
    "        main_words = re.sub('[^a-zA-Z]', ' ', ds[m])                                      # Retain only alphabets\n",
    "        main_words = (main_words.lower()).split()\n",
    "        main_words = [w for w in main_words if not w in set(stopwords.words('english'))]  # Remove stopwords\n",
    "        \n",
    "        lem = WordNetLemmatizer()\n",
    "        main_words = [lem.lemmatize(w) for w in main_words if len(w) > 1]                 # Group different forms of the same word\n",
    "        \n",
    "        main_words = ' '.join(main_words)\n",
    "        ds[m] = main_words\n",
    "    return ds\n",
    "\n",
    "test_processed = text_preprocess(dataset['rawContent'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786268,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"processed text\"] = test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe with processed data\n",
    "dataset.to_csv(\"Processed Data\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         new year day seward overlooking harbor beautif...\n",
       "1                                             happy newyear\n",
       "2         championed provision strengthen alaska economy...\n",
       "3         december senior appropriator helped write majo...\n",
       "4         december congressman young legacy live many wa...\n",
       "                                ...                        \n",
       "786263    violent mob assault capitol attempt prevent ca...\n",
       "786264    proud stand richard hudson protect second amen...\n",
       "786265    democrat repeatedly abused power achieve polit...\n",
       "786266    congratulate new colleague sworn office today ...\n",
       "786267    honored sworn today represent great people wyo...\n",
       "Name: processed text, Length: 786268, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"processed text\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786268, 4500)\n"
     ]
    }
   ],
   "source": [
    "X = dataset[\"processed text\"]\n",
    "td = TfidfVectorizer(max_features = 4500)\n",
    "X = td.fit_transform(X.apply(lambda x: np.str_(x))).toarray()# v.fit_transform(df['Review'].apply(lambda x: np.str_(x)))\n",
    "print(X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Relevant Non-Text Features to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dataset = dataset[['replyCount', 'retweetCount', 'likeCount', 'quoteCount',\n",
    "       'links', 'media', 'mentionedUsers', 'hashtags', 'Positive',\n",
    "       'Negative', 'Neutral']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "#adding non-text features\n",
    "X = np.concatenate((X, sub_dataset), 1)\n",
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Model (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy:  0.8062797926406772\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84    113665\n",
      "           1       0.80      0.71      0.76     82902\n",
      "\n",
      "    accuracy                           0.81    196567\n",
      "   macro avg       0.81      0.79      0.80    196567\n",
      "weighted avg       0.81      0.81      0.80    196567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training labels\n",
    "y = dataset[\"Party\"]\n",
    "\n",
    "# Split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25,\n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Training and predicting\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Model performance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('\\n Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('\\nClassification Report')\n",
    "print('======================================================')\n",
    "print('\\n', classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
