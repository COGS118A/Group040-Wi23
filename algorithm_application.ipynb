{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/cameronfaulkner/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cameronfaulkner/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rawContent</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>links</th>\n",
       "      <th>media</th>\n",
       "      <th>mentionedUsers</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Party</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Year’s Day in Seward overlooking the harbo...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy #NewYear!</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I championed provisions to strengthen Alaska’s...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>December: As senior Appropriator, I helped wri...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>December: Congressman Don Young’s legacy will ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          rawContent  replyCount  \\\n",
       "0  New Year’s Day in Seward overlooking the harbo...        44.0   \n",
       "1                                    Happy #NewYear!        19.0   \n",
       "2  I championed provisions to strengthen Alaska’s...         9.0   \n",
       "3  December: As senior Appropriator, I helped wri...        11.0   \n",
       "4  December: Congressman Don Young’s legacy will ...         5.0   \n",
       "\n",
       "   retweetCount  likeCount  quoteCount  links  media  mentionedUsers  \\\n",
       "0          12.0      239.0         2.0      0      3               0   \n",
       "1           4.0       22.0         1.0      0      0               0   \n",
       "2           5.0       19.0         0.0      0      0               0   \n",
       "3           6.0       28.0         3.0      0      1               0   \n",
       "4           9.0       46.0         1.0      0      1               0   \n",
       "\n",
       "   hashtags  Party  Positive  Negative  Neutral  \n",
       "0         0      1         1         0        0  \n",
       "1         1      1         1         0        0  \n",
       "2         0      1         1         0        0  \n",
       "3         0      1         1         0        0  \n",
       "4         0      1         1         0        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"/Users/cameronfaulkner/Documents/Cogs 118a/Final Project/Sentiment Added Dataset\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786268"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    new year day seward overlooking harbor beautif...\n",
       "1                                        happy newyear\n",
       "2    championed provision strengthen alaska economy...\n",
       "3    december senior appropriator helped write majo...\n",
       "4    december congressman young legacy live many wa...\n",
       "5    november long supported marriage equality beli...\n",
       "6    october great anchorage many alaskan nativefed...\n",
       "7    september senatordansullivan rep peltola govdu...\n",
       "8    september fall typhoon merbok produced widespr...\n",
       "9    august visit air station sitka comdtuscg uscg ...\n",
       "Name: rawContent, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"rawContent\"].iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(ds: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Apply NLP Preprocessing Techniques to the reviews.\n",
    "    \"\"\"\n",
    "    for m in range(len(ds)):\n",
    "        \n",
    "        main_words = re.sub('[^a-zA-Z]', ' ', ds[m])                                      # Retain only alphabets\n",
    "        main_words = (main_words.lower()).split()\n",
    "        main_words = [w for w in main_words if not w in set(stopwords.words('english'))]  # Remove stopwords\n",
    "        \n",
    "        lem = WordNetLemmatizer()\n",
    "        main_words = [lem.lemmatize(w) for w in main_words if len(w) > 1]                 # Group different forms of the same word\n",
    "        \n",
    "        main_words = ' '.join(main_words)\n",
    "        ds[m] = main_words\n",
    "    return ds\n",
    "\n",
    "test_processed = text_preprocess(dataset['rawContent'].iloc[0:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4500)\n"
     ]
    }
   ],
   "source": [
    "#X = dataset.iloc[:, 0].values\n",
    "X = test_processed.values\n",
    "#y = dataset.iloc[:, 1].values\n",
    "\n",
    "# Building a TF IDF matrix out of the corpus of reviews\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "td = TfidfVectorizer(max_features = 4500)\n",
    "X = td.fit_transform(X).toarray()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rawContent', 'replyCount', 'retweetCount', 'likeCount', 'quoteCount',\n",
       "       'links', 'media', 'mentionedUsers', 'hashtags', 'Party', 'Positive',\n",
       "       'Negative', 'Neutral'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dataset = dataset[['replyCount', 'retweetCount', 'likeCount', 'quoteCount',\n",
    "       'links', 'media', 'mentionedUsers', 'hashtags', 'Positive',\n",
    "       'Negative', 'Neutral']]\n",
    "sub_dataset = sub_dataset.iloc[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 11)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sub_dataset.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4500)\n",
      "(100000, 4511)\n",
      "\n",
      " Accuracy:  0.7823333333333333\n",
      "\n",
      "Classification Report\n",
      "======================================================\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.66      0.76     15466\n",
      "           1       0.72      0.91      0.80     14534\n",
      "\n",
      "    accuracy                           0.78     30000\n",
      "   macro avg       0.80      0.79      0.78     30000\n",
      "weighted avg       0.81      0.78      0.78     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#X = dataset.iloc[:, 0].values\n",
    "X = test_processed.values\n",
    "#y = dataset.iloc[:, 1].values\n",
    "y = dataset[\"Party\"][0:100000].values\n",
    "\n",
    "# Building a TF IDF matrix out of the corpus of reviews\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "td = TfidfVectorizer(max_features = 4500)\n",
    "X = td.fit_transform(X).toarray()\n",
    "print(np.shape(X))\n",
    "X = np.append(X,sub_dataset.to_numpy(),axis=1)\n",
    "print(np.shape(X))\n",
    "# Splitting into training & test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,\n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Training the classifier & predicting on test data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('\\n Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('\\nClassification Report')\n",
    "print('======================================================')\n",
    "print('\\n', classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
