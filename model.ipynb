{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#model evaluation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,  KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "\n",
    "#models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "# random state\n",
    "SEED = np.random.seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>links</th>\n",
       "      <th>media</th>\n",
       "      <th>mentionedUsers</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Party</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>processed text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>proud help direct million fta funding low emis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>grateful secure federal funding help mundelein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>http co yhlhatz iz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>discussing improve port operation prdirpuertos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>seems health expert governor abbott consulted ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   replyCount  retweetCount  likeCount  quoteCount  links  media  \\\n",
       "0         7.0           9.0       77.0         0.0      0      0   \n",
       "1         1.0           1.0       16.0         0.0      0      0   \n",
       "2        16.0           4.0       10.0         1.0      1      0   \n",
       "3         1.0           4.0       11.0         0.0      0      1   \n",
       "4         4.0          30.0       90.0         1.0      0      0   \n",
       "\n",
       "   mentionedUsers  hashtags  Party  Positive  Negative  Neutral  \\\n",
       "0               0         0      0         1         0        0   \n",
       "1               0         0      0         1         0        0   \n",
       "2               0         0      1         0         0        1   \n",
       "3               6         0      1         1         0        0   \n",
       "4               0         0      0         0         1        0   \n",
       "\n",
       "                                      processed text  \n",
       "0  proud help direct million fta funding low emis...  \n",
       "1  grateful secure federal funding help mundelein...  \n",
       "2                                 http co yhlhatz iz  \n",
       "3  discussing improve port operation prdirpuertos...  \n",
       "4  seems health expert governor abbott consulted ...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATHING ASSUMES \"Processed Data\" file is in the same directory as this file\n",
    "path = os.path.abspath(r'Processed Data')\n",
    "dataset = pd.read_csv(str(path))\n",
    "dataset = dataset.drop('rawContent', axis=1)\n",
    "\n",
    "# shuffle \n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "# training on 1/10th of the data\n",
    "dataset = dataset.iloc[:dataset.shape[0]//6]\n",
    "\n",
    "dataset.shape\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize Text Data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the processed text column\n",
    "X = dataset[\"processed text\"]\n",
    "td = TfidfVectorizer(max_features = 4500)\n",
    "X = td.fit_transform(X.apply(lambda x: np.str_(x))).toarray()# v.fit_transform(df['Review'].apply(lambda x: np.str_(x)))\n",
    "\n",
    "# concatenate the other relevant features to the vectorized processed text column\n",
    "sub_dataset = dataset.drop(['Party', 'processed text'], axis=1)\n",
    "X = np.concatenate((X, sub_dataset), 1)\n",
    "\n",
    "# extract ground truth labels\n",
    "y = dataset[\"Party\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25,random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(clf, X, y, X_test, y_test, graphs=True):\n",
    "    model = clf.fit(X, y)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = clf.score(X_test, y_test)\n",
    "\n",
    "    # print('\\n Accuracy: ', accuracy_score(y_test, pred))\n",
    "\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report \")\n",
    "    print('======================================================')\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "    if graphs == True:\n",
    "\n",
    "        #predicted probabilities\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Confusion Matrix\n",
    "        print(\"\\nConfusion Matrix \")\n",
    "        print('======================================================')\n",
    "        cm = confusion_matrix(y_test,pred)\n",
    "        sns.heatmap(cm, annot=True, cmap='rocket')\n",
    "        plt.xlabel('Predictions')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # ROC AUC curve\n",
    "        print(\"\\nROC AUC Curve \")\n",
    "        print('======================================================')\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        sns.set_style('whitegrid')\n",
    "        sns.set_palette('rocket_r')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.plot(fpr, tpr, label = 'AUC = %0.2f' % roc_auc)\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.plot([0, 1], [0, 1],'--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # Precision Recall Curve\n",
    "        print(\"\\nPrecision Recall Curve \")\n",
    "        print('======================================================')\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "    \n",
    "        sns.set_style('whitegrid')\n",
    "        sns.set_palette('rocket_r')\n",
    "        plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall curve')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(model,folds):\n",
    "    # model\n",
    "    clf = model\n",
    "    # Create a KFold object with k folds\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # mean acc\n",
    "    a = []\n",
    "    # Loop over the folds\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        # Split the data into training and test sets for this fold\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the classifier on the training set for this fold\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict the labels of the test set for this fold\n",
    "        y_hat = clf.predict(X_test)\n",
    "        # Compute the accuracy of the classifier on the test set for this fold\n",
    "        acc = accuracy_score(y_test, y_hat)\n",
    "        # Print the accuracy for this fold\n",
    "        print(f\"Fold accuracy: {acc:.3f}\")\n",
    "        a.append(acc)\n",
    "    print(f\"Mean Accuracy: {np.mean(a):.3f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report \n",
      "======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84     18995\n",
      "           1       0.80      0.73      0.76     13766\n",
      "\n",
      "    accuracy                           0.81     32761\n",
      "   macro avg       0.81      0.80      0.80     32761\n",
      "weighted avg       0.81      0.81      0.81     32761\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "evaluate_model(nb, X_train, y_train, X_test, y_test, graphs=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report \n",
      "======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84     18995\n",
      "           1       0.80      0.73      0.76     13766\n",
      "\n",
      "    accuracy                           0.81     32761\n",
      "   macro avg       0.81      0.80      0.80     32761\n",
      "weighted avg       0.81      0.81      0.81     32761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "params = {'alpha': [10,1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "clf = GridSearchCV(nb,params, cv=5)\n",
    "nb_gc  = evaluate_model(clf, X_train, y_train, X_test, y_test, graphs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "print(nb_gc.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Cross Validation Naive Bayes with Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.807\n",
      "Fold accuracy: 0.809\n",
      "Fold accuracy: 0.809\n",
      "Fold accuracy: 0.807\n",
      "Fold accuracy: 0.805\n",
      "Mean Accuracy: 0.807\n"
     ]
    }
   ],
   "source": [
    "k_fold(MultinomialNB(**nb_gc.best_params_),5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier()\n",
    "evaluate_model(sgd, X_train, y_train, X_test, y_test, graphs=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report \n",
      "======================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79     18995\n",
      "           1       0.76      0.52      0.62     13766\n",
      "\n",
      "    accuracy                           0.73     32761\n",
      "   macro avg       0.74      0.70      0.70     32761\n",
      "weighted avg       0.74      0.73      0.72     32761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "params = {\n",
    "    'loss': ['modified_huber', 'log_loss'],\n",
    "    'penalty': ['elasticnet', 'l2'],\n",
    "    'random_state': [SEED],\n",
    "    'early_stopping': [True]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(sgd,params)\n",
    "sgd_gc = evaluate_model(clf, X_train, y_train, X_test, y_test, graphs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'early_stopping': True, 'loss': 'log_loss', 'penalty': 'elasticnet', 'random_state': None}\n"
     ]
    }
   ],
   "source": [
    "print(sgd_gc.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Cross Validation SGD with Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.733\n",
      "Fold accuracy: 0.684\n",
      "Fold accuracy: 0.552\n",
      "Fold accuracy: 0.750\n",
      "Fold accuracy: 0.728\n",
      "Mean Accuracy: 0.689\n"
     ]
    }
   ],
   "source": [
    "params = {'early_stopping': True, 'loss': 'log_loss', 'penalty': 'l2', 'random_state': SEED}\n",
    "k_fold(SGDClassifier(**params),5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "evaluate_model(rf, X_train, y_train, X_test, y_test, graphs=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "params  = {\n",
    "    'n_estimators': [50, 100, 200], # number of trees in the forest\n",
    "    'max_depth': [4, 6], # max tree depth of each tree\n",
    "    # 'min_samples_split': [2, 5, 10], # min samples required to split node\n",
    "    'min_samples_leaf': [1, 2, 4], # min samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'] # number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(rf, params)\n",
    "rf_gc = evaluate_model(clf, X_train, y_train, X_test, y_test, graphs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gc.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Cross Validation Random Forest with Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold(RandomForestClassifier(**rf_gc.best_params_), 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = MultinomialNB()\n",
    "evaluate_model(ada, X_train, y_train, X_test, y_test, graphs=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "\n",
    "params = {\n",
    "   'learning_rate': [0.1, 0.001],\n",
    "   'max depth': [4,6,8]\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(ada,params)\n",
    "ada_gc = evaluate_model(clf, X_train, y_train, X_test, y_test, graphs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_gc.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Fold Cross Validation Adaboost with Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold(AdaBoostClassifier(**ada_gc.best_params_), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
